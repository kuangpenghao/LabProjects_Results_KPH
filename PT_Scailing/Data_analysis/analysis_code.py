# -*- coding: utf-8 -*-
"""
è°ƒå‚ç»“æœåˆ†ææ¨¡æ¿
è¾“å…¥ï¼šè°ƒå‚ç»“æœ.xlsxï¼ˆåŒ…å«10ä¸ªå¸ƒå°”å¼€å…³åˆ— + eval/loss, eval/accuracyï¼‰
è¾“å‡ºï¼šç‰¹å¾é‡è¦æ€§ã€äº¤äº’æ•ˆåº”ã€æ¨èé…ç½®
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
import xgboost as xgb
import shap
import itertools
import os


def load_data(path="è°ƒå‚ç»“æœ.xlsx"):
    df = pd.read_excel(path)

    # è‡ªåŠ¨è¯†åˆ«10ä¸ªå¼€å…³åˆ—ï¼ˆæ ¹æ®ä½ æä¾›çš„åˆ—åï¼‰
    switch_cols = [
        'no_mask_diagonal',
        'no_vo_rope',
        'untie_attn_weights',
        'untie_ffn_weights',
        'untie_layerwise_weights',
        'use_ffn_after_attn',
        'use_gated_ffn',
        'use_rms_norm',
        'use_single_message_attn',
        'use_std_residual'
    ]

    missing = set(switch_cols) - set(df.columns)
    if missing:
        raise ValueError(f"ç¼ºå¤±å¼€å…³åˆ—: {missing}")

    df_switch = df[switch_cols].astype(int)
    y_loss = df['eval/loss']
    y_acc = df['eval/accuracy']

    print(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡å®éªŒè®°å½•")
    return df, switch_cols, df_switch, y_loss, y_acc


def train_xgb_and_shap(X, y, n_estimators=200, max_depth=5, learning_rate=0.1, random_state=42):
    print("\nğŸ¤– æ­£åœ¨è®­ç»ƒ XGBoost æ¨¡å‹å¹¶è®¡ç®— SHAP å€¼...")
    model = xgb.XGBRegressor(
        n_estimators=n_estimators,
        max_depth=max_depth,
        learning_rate=learning_rate,
        random_state=random_state
    )
    model.fit(X, y)

    explainer = shap.TreeExplainer(model)
    shap_values = explainer.shap_values(X)

    plt.rcParams['font.sans-serif'] = ['SimHei']  # æ”¯æŒä¸­æ–‡ï¼ˆå¯é€‰ï¼‰
    plt.rcParams['axes.unicode_minus'] = False

    return model, explainer, shap_values


def plot_shap_summary(shap_values, X):
    plt.figure(figsize=(10, 6))
    shap.summary_plot(shap_values, X, plot_type="bar", show=False)
    plt.title("SHAP ç‰¹å¾é‡è¦æ€§ï¼ˆå¯¹ eval/loss çš„å½±å“ï¼‰")
    plt.tight_layout()
    plt.savefig("shap_importance.png", dpi=150)
    plt.show()

    plt.figure(figsize=(10, 8))
    shap.summary_plot(shap_values, X, show=False)
    plt.title("SHAP æ±‡æ€»å›¾ï¼ˆçº¢=å¼€å…³å¼€ï¼Œè“=å¼€å…³å…³ï¼‰")
    plt.tight_layout()
    plt.savefig("shap_summary.png", dpi=150)
    plt.show()


def top5_recommendation(df, switch_cols):
    # è®¡ç®—å¹¶ä¿å­˜ Top-5 åˆ° Excelï¼ˆä¸ç›´æ¥è¾“å‡ºåˆ°ç»ˆç«¯ï¼‰
    top5 = df.nlargest(5, 'eval/accuracy')[switch_cols + ['eval/accuracy', 'eval/loss', 'Name']]
    top5.to_excel("top5_recommendation.xlsx", index=False)

    # ä¿å­˜ Top-5 ä¸­å„å¼€å…³å¼€å¯æ¯”ä¾‹
    top5_switch_mean = top5[switch_cols].mean().sort_values(ascending=False)
    top5_switch_mean.to_frame(name='fraction_on').to_excel("top5_switch_fraction.xlsx")

    return top5


def compute_shap_interactions(explainer, X, switch_cols):
    print("\nğŸ”„ æ­£åœ¨è®¡ç®— SHAP äº¤äº’å€¼ï¼ˆå¯èƒ½è¾ƒæ…¢ï¼‰...")
    shap_interaction = explainer.shap_interaction_values(X)
    interaction_matrix = np.abs(shap_interaction).mean(axis=0)
    plt.figure(figsize=(10, 8))
    sns.heatmap(interaction_matrix, xticklabels=switch_cols, yticklabels=switch_cols, cmap="Blues")
    plt.title("SHAP äº¤äº’å¼ºåº¦ï¼ˆç»å¯¹å€¼å‡å€¼ï¼‰")
    plt.tight_layout()
    plt.savefig("shap_interactions.png", dpi=150)
    plt.show()

    return shap_interaction, interaction_matrix


def pairwise_scan(df, X, shap_values, shap_interaction, switch_cols, out_dir="interaction_analysis"):
    print("\nğŸ” æ­£åœ¨æ‰§è¡Œå…¨å±€äº¤äº’æ‰«æï¼ˆæ¯å¼€å…³ vs å…¶ä½™9ä¸ªï¼‰...")
    os.makedirs(out_dir, exist_ok=True)

    interaction_summary = []

    for main_feat, other_feat in itertools.combinations(switch_cols, 2):
        group = df.groupby([main_feat, other_feat])['eval/loss'].agg(['mean', 'count'])
        if group.empty:
            continue

        best_combo = group.loc[group['mean'].idxmin()]
        best_val = best_combo['mean']
        best_count = int(best_combo['count'])
        best_config = group['mean'].idxmin()  # (switch1_val, switch2_val)

        try:
            idx1 = X.columns.get_loc(main_feat)
            idx2 = X.columns.get_loc(other_feat)
            interaction_strength = np.abs(shap_interaction[:, idx1, idx2]).mean()
        except Exception:
            interaction_strength = np.nan

        plt.figure(figsize=(6, 4))
        shap.dependence_plot(
            main_feat,
            shap_values,
            X,
            interaction_index=other_feat,
            show=False,
            x_jitter=0.3,
            alpha=0.7
        )
        plt.title(f"{main_feat} vs {other_feat}")
        plt.tight_layout()
        plt.savefig(f"{out_dir}/{main_feat}_vs_{other_feat}.png", dpi=120)
        plt.close()

        interaction_summary.append({
            'switch1': main_feat,
            'switch2': other_feat,
            'best_loss': best_val,
            'best_count': best_count,
            'switch1_val': best_config[0],
            'switch2_val': best_config[1],
            'interaction_strength': interaction_strength
        })

    summary_df = pd.DataFrame(interaction_summary)
    summary_df = summary_df.sort_values('best_loss')
    summary_df.to_excel("interaction_summary_pairs.xlsx", index=False)

    # ä¸åœ¨ç»ˆç«¯æ‰“å°è¡¨æ ¼ï¼Œç›´æ¥è¿”å› DataFrameï¼ˆæ–‡ä»¶å·²ä¿å­˜ï¼‰
    print(f"âœ… å…¨å±€äº¤äº’æ‰«æå®Œæˆï¼Œæ‘˜è¦å·²ä¿å­˜ä¸º interaction_summary_pairs.xlsxï¼ˆå…± {len(interaction_summary)} æ¡ï¼‰")
    return summary_df


def three_way_scan(df, X, shap_interaction, switch_cols, out_dir="interaction_analysis"):
    print("\nğŸ” æ­£åœ¨æ‰§è¡Œä¸‰å…ƒç»„åˆæ‰«æï¼ˆæ¯ 3 ä¸ªå¼€å…³ä¸€ç»„ï¼‰...")
    interaction_summary_three = []

    for trio in itertools.combinations(switch_cols, 3):
        a, b, c = trio
        group3 = df.groupby([a, b, c])['eval/loss'].agg(['mean', 'count'])
        if group3.empty:
            continue

        best_combo3 = group3.loc[group3['mean'].idxmin()]
        best_val3 = best_combo3['mean']
        best_count3 = int(best_combo3['count'])
        best_config3 = group3['mean'].idxmin()  # (a_val, b_val, c_val)

        try:
            i1 = X.columns.get_loc(a)
            i2 = X.columns.get_loc(b)
            i3 = X.columns.get_loc(c)
            pair12 = np.abs(shap_interaction[:, i1, i2]).mean()
            pair13 = np.abs(shap_interaction[:, i1, i3]).mean()
            pair23 = np.abs(shap_interaction[:, i2, i3]).mean()
            tri_interaction_strength = np.mean([pair12, pair13, pair23])
        except Exception:
            tri_interaction_strength = np.nan

        try:
            df_plot = group3.reset_index()
            df_plot['combo'] = df_plot.apply(lambda r: f"{int(r[a])}{int(r[b])}{int(r[c])}", axis=1)
            df_plot = df_plot.sort_values('mean')

            plt.figure(figsize=(8, 4))
            sns.barplot(data=df_plot, x='combo', y='mean', palette='viridis')
            plt.xlabel(f"ç»„åˆ({a},{b},{c}) è®¾ç½® (a b c)")
            plt.ylabel('mean eval/loss')
            plt.title(f"ä¸‰å…ƒç»„åˆ Loss: {a} {b} {c}")
            plt.tight_layout()
            plt.savefig(f"{out_dir}/three_{a}_{b}_{c}.png", dpi=140)
            plt.close()
        except Exception:
            pass

        interaction_summary_three.append({
            'switch1': a,
            'switch2': b,
            'switch3': c,
            'best_loss': best_val3,
            'best_count': best_count3,
            'switch1_val': best_config3[0],
            'switch2_val': best_config3[1],
            'switch3_val': best_config3[2],
            'interaction_strength': tri_interaction_strength
        })

    if interaction_summary_three:
        summary3_df = pd.DataFrame(interaction_summary_three)
        summary3_df = summary3_df.sort_values('best_loss')
        summary3_df.to_excel("interaction_summary_three.xlsx", index=False)
        print(f"âœ… ä¸‰å…ƒç»„åˆæ‰«æå®Œæˆï¼Œæ‘˜è¦å·²ä¿å­˜ä¸º interaction_summary_three.xlsxï¼ˆå…± {len(interaction_summary_three)} æ¡ï¼‰")
        return summary3_df
    else:
        print("âš ï¸ æœªç”Ÿæˆä»»ä½•ä¸‰å…ƒç»„åˆæ‘˜è¦ï¼ˆæ•°æ®å¯èƒ½ä¸è¶³ï¼‰")
        return pd.DataFrame()


def compute_three_way_model_interactions(model, X, switch_cols, sample_size=200, out_file="three_way_model_interactions.xlsx"):
    """
    è®¡ç®—åŸºäºæ¨¡å‹é¢„æµ‹çš„ä¸‰å…ƒäº¤äº’å¼ºåº¦ï¼ˆå¯¹æ¯ä¸ªä¸‰å…ƒç»„ï¼Œä½¿ç”¨æœ‰é™å·®åˆ†åœ¨æ ·æœ¬å­é›†ä¸Šè®¡ç®—ä¸‰é˜¶äº¤äº’é‡ï¼‰

    Returns a DataFrame with columns: switch1, switch2, switch3, model_interaction_strength
    """
    print("\nğŸ”¢ è®¡ç®—åŸºäºæ¨¡å‹çš„ä¸‰å…ƒäº¤äº’å¼ºåº¦ï¼ˆå¯èƒ½è¾ƒæ…¢ï¼‰...")
    n_samples = len(X)
    sample_size = min(sample_size, n_samples)
    rng = np.random.default_rng(42)

    results = []
    combos = list(itertools.product([0, 1], repeat=3))
    coeffs = np.array([(-1) ** (3 - sum(bits)) for bits in combos])

    # é¢„è½¬æ¢ X ä¸º numpy array ä»¥åŠ é€Ÿå¤åˆ¶å’Œä¿®æ”¹
    X_vals = X.values
    for trio in itertools.combinations(switch_cols, 3):
        a, b, c = trio
        i1 = X.columns.get_loc(a)
        i2 = X.columns.get_loc(b)
        i3 = X.columns.get_loc(c)

        # éšæœºæŠ½æ ·ç´¢å¼•
        if n_samples <= sample_size:
            sample_idx = np.arange(n_samples)
        else:
            sample_idx = rng.choice(n_samples, size=sample_size, replace=False)

        tri_effects = []
        try:
            for s_idx in sample_idx:
                base = X_vals[s_idx].reshape(1, -1)
                variants = np.repeat(base, 8, axis=0).copy()
                for k, bits in enumerate(combos):
                    variants[k, i1] = bits[0]
                    variants[k, i2] = bits[1]
                    variants[k, i3] = bits[2]

                preds = model.predict(variants)
                tri_val = np.sum(coeffs * preds) / 8.0
                tri_effects.append(tri_val)

            model_strength = float(np.mean(np.abs(tri_effects)))
        except Exception:
            model_strength = np.nan

        results.append({
            'switch1': a,
            'switch2': b,
            'switch3': c,
            'model_interaction_strength': model_strength
        })

    res_df = pd.DataFrame(results)
    if not res_df.empty:
        res_df = res_df.sort_values('model_interaction_strength', ascending=False)
        res_df.to_excel(out_file, index=False)
        print(f"âœ… ä¸‰å…ƒæ¨¡å‹äº¤äº’å¼ºåº¦è®¡ç®—å®Œæˆï¼Œç»“æœå·²ä¿å­˜ä¸º {out_file}ï¼ˆå…± {len(res_df)} æ¡ï¼‰")
    else:
        print("âš ï¸ æœªè®¡ç®—åˆ°ä»»ä½•ä¸‰å…ƒæ¨¡å‹äº¤äº’å¼ºåº¦ï¼ˆæ•°æ®å¯èƒ½ä¸è¶³ï¼‰")

    return res_df


def main():
    df, switch_cols, df_switch, y_loss, y_acc = load_data()

    X = df_switch.copy()
    y = y_loss

    model, explainer, shap_values = train_xgb_and_shap(X, y)
    plot_shap_summary(shap_values, X)
    top5 = top5_recommendation(df, switch_cols)
    shap_interaction, interaction_matrix = compute_shap_interactions(explainer, X, switch_cols)
    three_model_df = compute_three_way_model_interactions(model, X, switch_cols, sample_size=200, out_file="three_way_model_interactions.xlsx")
    summary2_df = pairwise_scan(df, X, shap_values, shap_interaction, switch_cols)
    summary3_df = three_way_scan(df, X, shap_interaction, switch_cols)


if __name__ == "__main__":
    main()


