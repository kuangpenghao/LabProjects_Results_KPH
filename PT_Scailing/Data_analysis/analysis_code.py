# -*- coding: utf-8 -*-
"""
è°ƒå‚ç»“æœåˆ†ææ¨¡æ¿
è¾“å…¥ï¼šè°ƒå‚ç»“æœ.xlsxï¼ˆåŒ…å«10ä¸ªå¸ƒå°”å¼€å…³åˆ— + eval/loss, eval/accuracyï¼‰
è¾“å‡ºï¼šç‰¹å¾é‡è¦æ€§ã€äº¤äº’æ•ˆåº”ã€æ¨èé…ç½®

æ–°å¢åŠŸèƒ½ï¼š
1. analyze_fixed_switches(df, switch_list, value_list, out_dir, loss_col)
   - å›ºå®šæŒ‡å®šå¼€å…³çš„å–å€¼ï¼Œåˆ†ææ»¡è¶³æ¡ä»¶çš„å®éªŒè®°å½•çš„ loss åˆ†å¸ƒæƒ…å†µ
   - ç”Ÿæˆç®±çº¿å›¾ã€å°æç´å›¾ã€ç›´æ–¹å›¾+KDEã€ECDF ç­‰å¯è§†åŒ–
   - è¾“å‡ºç»Ÿè®¡æ‘˜è¦ï¼ˆå‡å€¼ã€æ–¹å·®ã€æå€¼ç­‰ï¼‰ä¸º Excel æ–‡ä»¶

2. compare_fixed_switches(df, conditions_list, out_dir, loss_col)
   - å¯¹æ¯”å¤šç»„å›ºå®šå¼€å…³æ¡ä»¶ä¸‹çš„ loss åˆ†å¸ƒæƒ…å†µ
   - ç”Ÿæˆè”åˆçš„æ¯”è¾ƒå›¾è¡¨ï¼šå¹¶æ’ç®±çº¿å›¾/å°æç´å›¾ã€é‡å ç›´æ–¹å›¾+KDEã€ECDFå¯¹æ¯”ã€ç»Ÿè®¡é‡æŸ±çŠ¶å›¾
   - æ”¯æŒå¤šæ¡ä»¶åŒæ—¶æ¯”è¾ƒåˆ†æ

3. auto_pairwise_analysis(df, switch_cols, base_out_dir, loss_col)
   - è‡ªåŠ¨å¯¹æ‰€æœ‰å¼€å…³ä¸¤ä¸¤ç»„åˆè¿›è¡Œå››çŠ¶æ€å¯¹æ¯”åˆ†æï¼ˆ00, 01, 10, 11ï¼‰
   - ä¸ºæ¯ä¸ªç»„åˆåˆ›å»ºå­æ–‡ä»¶å¤¹ï¼ŒåŒ…å«å®Œæ•´çš„å¯¹æ¯”åˆ†æç»“æœ
   - ç”Ÿæˆæ€»ç»“æŠ¥å‘Šå’Œå½±å“åŠ›æ’è¡Œæ¦œï¼Œæ‰¾å‡ºæœ€æœ‰å½±å“åŠ›çš„å¼€å…³ç»„åˆ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
import xgboost as xgb
import shap
import itertools
import os


def load_data(path="D:\_SHTU_\TKW_Lab\LabProjects_Results_KPH\PT_Scailing\Data_analysis\sweep.xlsx"):
    df = pd.read_excel(path)

    # è‡ªåŠ¨è¯†åˆ«10ä¸ªå¼€å…³åˆ—ï¼ˆæ ¹æ®ä½ æä¾›çš„åˆ—åï¼‰
    switch_cols = [
        'no_mask_diagonal',
        'no_vo_rope',
        'untie_attn_weights',
        'untie_ffn_weights',
        'untie_layerwise_weights',
        'use_ffn_after_attn',
        'use_gated_ffn',
        'use_rms_norm',
        'use_single_message_attn',
        'use_std_residual'
    ]

    missing = set(switch_cols) - set(df.columns)
    if missing:
        raise ValueError(f"ç¼ºå¤±å¼€å…³åˆ—: {missing}")

    df_switch = df[switch_cols].astype(int)
    y_loss = df['eval/loss']
    y_acc = df['eval/accuracy']

    print(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡å®éªŒè®°å½•")
    return df, switch_cols, df_switch, y_loss, y_acc


def train_xgb_and_shap(X, y, n_estimators=200, max_depth=5, learning_rate=0.1, random_state=42):
    print("\nğŸ¤– æ­£åœ¨è®­ç»ƒ XGBoost æ¨¡å‹å¹¶è®¡ç®— SHAP å€¼...")
    model = xgb.XGBRegressor(
        n_estimators=n_estimators,
        max_depth=max_depth,
        learning_rate=learning_rate,
        random_state=random_state
    )
    model.fit(X, y)

    explainer = shap.TreeExplainer(model)
    shap_values = explainer.shap_values(X)

    plt.rcParams['font.sans-serif'] = ['SimHei']  # æ”¯æŒä¸­æ–‡ï¼ˆå¯é€‰ï¼‰
    plt.rcParams['axes.unicode_minus'] = False

    return model, explainer, shap_values


def plot_shap_summary(shap_values, X):
    plt.figure(figsize=(10, 6))
    shap.summary_plot(shap_values, X, plot_type="bar", show=False)
    plt.title("SHAP ç‰¹å¾é‡è¦æ€§ï¼ˆå¯¹ eval/loss çš„å½±å“ï¼‰")
    plt.tight_layout()
    plt.savefig("shap_importance.png", dpi=150)
    plt.show()

    plt.figure(figsize=(10, 8))
    shap.summary_plot(shap_values, X, show=False)
    plt.title("SHAP æ±‡æ€»å›¾ï¼ˆçº¢=å¼€å…³å¼€ï¼Œè“=å¼€å…³å…³ï¼‰")
    plt.tight_layout()
    plt.savefig("shap_summary.png", dpi=150)
    plt.show()


def top5_recommendation(df, switch_cols):
    # è®¡ç®—å¹¶ä¿å­˜ Top-5 åˆ° Excelï¼ˆä¸ç›´æ¥è¾“å‡ºåˆ°ç»ˆç«¯ï¼‰
    top5 = df.nlargest(390, 'eval/accuracy')[switch_cols + ['eval/accuracy', 'eval/loss', 'Name']]
    #top5.to_excel("top5_recommendation.xlsx", index=False)

    # ä¿å­˜ Top-5 ä¸­å„å¼€å…³å¼€å¯æ¯”ä¾‹
    top5_switch_mean = top5[switch_cols].mean().sort_values(ascending=False)
    top5_switch_mean.to_frame(name='fraction_on').to_excel("top390_switch_fraction.xlsx")

    return top5


def compute_shap_interactions(explainer, X, switch_cols):
    print("\nğŸ”„ æ­£åœ¨è®¡ç®— SHAP äº¤äº’å€¼ï¼ˆå¯èƒ½è¾ƒæ…¢ï¼‰...")
    shap_interaction = explainer.shap_interaction_values(X)
    interaction_matrix = np.abs(shap_interaction).mean(axis=0)
    plt.figure(figsize=(10, 8))
    sns.heatmap(interaction_matrix, xticklabels=switch_cols, yticklabels=switch_cols, cmap="Blues")
    plt.title("SHAP äº¤äº’å¼ºåº¦ï¼ˆç»å¯¹å€¼å‡å€¼ï¼‰")
    plt.tight_layout()
    plt.savefig("shap_interactions.png", dpi=150)
    plt.show()

    return shap_interaction, interaction_matrix


def pairwise_scan(df, X, shap_values, shap_interaction, switch_cols, out_dir="interaction_analysis"):
    print("\nğŸ” æ­£åœ¨æ‰§è¡Œå…¨å±€äº¤äº’æ‰«æï¼ˆæ¯å¼€å…³ vs å…¶ä½™9ä¸ªï¼‰...")
    os.makedirs(out_dir, exist_ok=True)

    interaction_summary = []

    for main_feat, other_feat in itertools.combinations(switch_cols, 2):
        group = df.groupby([main_feat, other_feat])['eval/loss'].agg(['mean', 'count'])
        if group.empty:
            continue

        best_combo = group.loc[group['mean'].idxmin()]
        best_val = best_combo['mean']
        best_count = int(best_combo['count'])
        best_config = group['mean'].idxmin()  # (switch1_val, switch2_val)

        try:
            idx1 = X.columns.get_loc(main_feat)
            idx2 = X.columns.get_loc(other_feat)
            interaction_strength = np.abs(shap_interaction[:, idx1, idx2]).mean()
        except Exception:
            interaction_strength = np.nan

        plt.figure(figsize=(6, 4))
        shap.dependence_plot(
            main_feat,
            shap_values,
            X,
            interaction_index=other_feat,
            show=False,
            x_jitter=0.3,
            alpha=0.7
        )
        plt.title(f"{main_feat} vs {other_feat}")
        plt.tight_layout()
        plt.savefig(f"{out_dir}/{main_feat}_vs_{other_feat}.png", dpi=120)
        plt.close()

        interaction_summary.append({
            'switch1': main_feat,
            'switch2': other_feat,
            'best_loss': best_val,
            'best_count': best_count,
            'switch1_val': best_config[0],
            'switch2_val': best_config[1],
            'interaction_strength': interaction_strength
        })

    summary_df = pd.DataFrame(interaction_summary)
    summary_df = summary_df.sort_values('best_loss')
    summary_df.to_excel("interaction_summary_pairs.xlsx", index=False)

    # ä¸åœ¨ç»ˆç«¯æ‰“å°è¡¨æ ¼ï¼Œç›´æ¥è¿”å› DataFrameï¼ˆæ–‡ä»¶å·²ä¿å­˜ï¼‰
    print(f"âœ… å…¨å±€äº¤äº’æ‰«æå®Œæˆï¼Œæ‘˜è¦å·²ä¿å­˜ä¸º interaction_summary_pairs.xlsxï¼ˆå…± {len(interaction_summary)} æ¡ï¼‰")
    return summary_df


def three_way_scan(df, X, shap_interaction, switch_cols, out_dir="interaction_analysis"):
    print("\nğŸ” æ­£åœ¨æ‰§è¡Œä¸‰å…ƒç»„åˆæ‰«æï¼ˆæ¯ 3 ä¸ªå¼€å…³ä¸€ç»„ï¼‰...")
    interaction_summary_three = []

    for trio in itertools.combinations(switch_cols, 3):
        a, b, c = trio
        group3 = df.groupby([a, b, c])['eval/loss'].agg(['mean', 'count'])
        if group3.empty:
            continue

        best_combo3 = group3.loc[group3['mean'].idxmin()]
        best_val3 = best_combo3['mean']
        best_count3 = int(best_combo3['count'])
        best_config3 = group3['mean'].idxmin()  # (a_val, b_val, c_val)

        try:
            i1 = X.columns.get_loc(a)
            i2 = X.columns.get_loc(b)
            i3 = X.columns.get_loc(c)
            pair12 = np.abs(shap_interaction[:, i1, i2]).mean()
            pair13 = np.abs(shap_interaction[:, i1, i3]).mean()
            pair23 = np.abs(shap_interaction[:, i2, i3]).mean()
            tri_interaction_strength = np.mean([pair12, pair13, pair23])
        except Exception:
            tri_interaction_strength = np.nan

        try:
            df_plot = group3.reset_index()
            df_plot['combo'] = df_plot.apply(lambda r: f"{int(r[a])}{int(r[b])}{int(r[c])}", axis=1)
            df_plot = df_plot.sort_values('mean')

            plt.figure(figsize=(8, 4))
            sns.barplot(data=df_plot, x='combo', y='mean', palette='viridis')
            plt.xlabel(f"ç»„åˆ({a},{b},{c}) è®¾ç½® (a b c)")
            plt.ylabel('mean eval/loss')
            plt.title(f"ä¸‰å…ƒç»„åˆ Loss: {a} {b} {c}")
            plt.tight_layout()
            plt.savefig(f"{out_dir}/three_{a}_{b}_{c}.png", dpi=140)
            plt.close()
        except Exception:
            pass

        interaction_summary_three.append({
            'switch1': a,
            'switch2': b,
            'switch3': c,
            'best_loss': best_val3,
            'best_count': best_count3,
            'switch1_val': best_config3[0],
            'switch2_val': best_config3[1],
            'switch3_val': best_config3[2],
            'interaction_strength': tri_interaction_strength
        })

    if interaction_summary_three:
        summary3_df = pd.DataFrame(interaction_summary_three)
        summary3_df = summary3_df.sort_values('best_loss')
        summary3_df.to_excel("interaction_summary_three.xlsx", index=False)
        print(f"âœ… ä¸‰å…ƒç»„åˆæ‰«æå®Œæˆï¼Œæ‘˜è¦å·²ä¿å­˜ä¸º interaction_summary_three.xlsxï¼ˆå…± {len(interaction_summary_three)} æ¡ï¼‰")
        return summary3_df
    else:
        print("âš ï¸ æœªç”Ÿæˆä»»ä½•ä¸‰å…ƒç»„åˆæ‘˜è¦ï¼ˆæ•°æ®å¯èƒ½ä¸è¶³ï¼‰")
        return pd.DataFrame()


def compute_three_way_model_interactions(model, X, switch_cols, sample_size=200, out_file="three_way_model_interactions.xlsx"):
    """
    è®¡ç®—åŸºäºæ¨¡å‹é¢„æµ‹çš„ä¸‰å…ƒäº¤äº’å¼ºåº¦ï¼ˆå¯¹æ¯ä¸ªä¸‰å…ƒç»„ï¼Œä½¿ç”¨æœ‰é™å·®åˆ†åœ¨æ ·æœ¬å­é›†ä¸Šè®¡ç®—ä¸‰é˜¶äº¤äº’é‡ï¼‰

    Returns a DataFrame with columns: switch1, switch2, switch3, model_interaction_strength
    """
    print("\nğŸ”¢ è®¡ç®—åŸºäºæ¨¡å‹çš„ä¸‰å…ƒäº¤äº’å¼ºåº¦ï¼ˆå¯èƒ½è¾ƒæ…¢ï¼‰...")
    n_samples = len(X)
    sample_size = min(sample_size, n_samples)
    rng = np.random.default_rng(42)

    results = []
    combos = list(itertools.product([0, 1], repeat=3))
    coeffs = np.array([(-1) ** (3 - sum(bits)) for bits in combos])

    # é¢„è½¬æ¢ X ä¸º numpy array ä»¥åŠ é€Ÿå¤åˆ¶å’Œä¿®æ”¹
    X_vals = X.values
    for trio in itertools.combinations(switch_cols, 3):
        a, b, c = trio
        i1 = X.columns.get_loc(a)
        i2 = X.columns.get_loc(b)
        i3 = X.columns.get_loc(c)

        # éšæœºæŠ½æ ·ç´¢å¼•
        if n_samples <= sample_size:
            sample_idx = np.arange(n_samples)
        else:
            sample_idx = rng.choice(n_samples, size=sample_size, replace=False)

        tri_effects = []
        try:
            for s_idx in sample_idx:
                base = X_vals[s_idx].reshape(1, -1)
                variants = np.repeat(base, 8, axis=0).copy()
                for k, bits in enumerate(combos):
                    variants[k, i1] = bits[0]
                    variants[k, i2] = bits[1]
                    variants[k, i3] = bits[2]

                preds = model.predict(variants)
                tri_val = np.sum(coeffs * preds) / 8.0
                tri_effects.append(tri_val)

            model_strength = float(np.mean(np.abs(tri_effects)))
        except Exception:
            model_strength = np.nan

        results.append({
            'switch1': a,
            'switch2': b,
            'switch3': c,
            'model_interaction_strength': model_strength
        })

    res_df = pd.DataFrame(results)
    if not res_df.empty:
        res_df = res_df.sort_values('model_interaction_strength', ascending=False)
        res_df.to_excel(out_file, index=False)
        print(f"âœ… ä¸‰å…ƒæ¨¡å‹äº¤äº’å¼ºåº¦è®¡ç®—å®Œæˆï¼Œç»“æœå·²ä¿å­˜ä¸º {out_file}ï¼ˆå…± {len(res_df)} æ¡ï¼‰")
    else:
        print("âš ï¸ æœªè®¡ç®—åˆ°ä»»ä½•ä¸‰å…ƒæ¨¡å‹äº¤äº’å¼ºåº¦ï¼ˆæ•°æ®å¯èƒ½ä¸è¶³ï¼‰")

    return res_df

def compare_fixed_switches(df, conditions_list, out_dir="compare_fixed_switches", loss_col='eval/loss'):
    """
    å¯¹æ¯”å¤šç»„å›ºå®šå¼€å…³æ¡ä»¶ä¸‹çš„ loss åˆ†å¸ƒæƒ…å†µï¼Œç”Ÿæˆè”åˆçš„æ¯”è¾ƒå›¾è¡¨ã€‚
    
    å‚æ•°:
    - df: åŸå§‹ DataFrameï¼ˆåŒ…å«å¼€å…³åˆ—ä¸ `loss_col`ï¼‰
    - conditions_list: æ¡ä»¶åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«ï¼š
        {
            'switch_list': ['å¼€å…³1', 'å¼€å…³2', ...],
            'value_list': [å–å€¼1, å–å€¼2, ...],
            'label': 'æ¡ä»¶æ ‡ç­¾'  # å¯é€‰ï¼Œç”¨äºå›¾ä¾‹æ˜¾ç¤º
        }
    - out_dir: è¾“å‡ºç›®å½•ï¼ˆå›¾ç‰‡ä¸ç»Ÿè®¡è¡¨ä¿å­˜åˆ°æ­¤å¤„ï¼‰
    - loss_col: è¦åˆ†æçš„æŸå¤±åˆ—åï¼ˆé»˜è®¤ 'eval/loss'ï¼‰
    
    è¿”å›:
    - combined_stats_df: åŒ…å«æ‰€æœ‰æ¡ä»¶ç»Ÿè®¡é‡çš„å¯¹æ¯” DataFrame
    - combined_data: åŒ…å«æ‰€æœ‰æ¡ä»¶æ•°æ®çš„ DataFrameï¼ˆç”¨äºè¿›ä¸€æ­¥åˆ†æï¼‰
    """
    os.makedirs(out_dir, exist_ok=True)
    
    all_stats = []
    all_data = []
    
    # ä¸ºæ¯ä¸ªæ¡ä»¶æå–æ•°æ®å’Œç»Ÿè®¡é‡
    for i, condition in enumerate(conditions_list):
        switch_list = condition['switch_list']
        value_list = condition['value_list']
        label = condition.get('label', f"æ¡ä»¶{i+1}: " + ",".join([f"{s}={v}" for s, v in zip(switch_list, value_list)]))
        
        # è¿‡æ»¤æ•°æ®
        mask = np.ones(len(df), dtype=bool)
        for sw, val in zip(switch_list, value_list):
            if sw not in df.columns:
                raise ValueError(f"å¼€å…³åˆ—ä¸å­˜åœ¨: {sw}")
            mask &= (df[sw] == int(val))
        
        subset = df[mask].copy()
        n = len(subset)
        
        if n == 0:
            print(f"âš ï¸ æ¡ä»¶ {label} æ— ç¬¦åˆæ¡ä»¶çš„è®°å½•")
            continue
            
        # ç»Ÿè®¡é‡
        vals = subset[loss_col].dropna()
        stats = vals.describe()
        stats_dict = {
            'condition': label,
            'count': int(stats['count']),
            'mean': float(stats['mean']),
            'std': float(stats['std']) if not np.isnan(stats['std']) else np.nan,
            'min': float(stats['min']),
            'q1': float(stats['25%']),
            'median': float(stats['50%']),
            'q3': float(stats['75%']),
            'max': float(stats['max'])
        }
        all_stats.append(stats_dict)
        
        # ä¸ºè”åˆåˆ†æå‡†å¤‡æ•°æ®
        subset_for_plot = subset[[loss_col]].copy()
        subset_for_plot['condition'] = label
        subset_for_plot['condition_idx'] = i
        all_data.append(subset_for_plot)
    
    if not all_stats:
        print("âš ï¸ æ²¡æœ‰ä»»ä½•æ¡ä»¶äº§ç”Ÿæœ‰æ•ˆæ•°æ®")
        return pd.DataFrame(), pd.DataFrame()
    
    # åˆå¹¶æ•°æ®
    combined_stats_df = pd.DataFrame(all_stats)
    combined_data = pd.concat(all_data, ignore_index=True)
    
    # ä¿å­˜ç»Ÿè®¡å¯¹æ¯”è¡¨
    combined_stats_df.to_excel(os.path.join(out_dir, "comparison_stats.xlsx"), index=False)
    
    # 1) å¹¶æ’ç®±çº¿å›¾æ¯”è¾ƒ
    plt.figure(figsize=(12, 6))
    sns.boxplot(data=combined_data, x='condition', y=loss_col, palette='Set2')
    plt.title('å¤šæ¡ä»¶ Loss åˆ†å¸ƒå¯¹æ¯” (ç®±çº¿å›¾)')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.savefig(os.path.join(out_dir, "comparison_boxplot.png"), dpi=150)
    plt.close()
    
    # 2) å¹¶æ’å°æç´å›¾æ¯”è¾ƒ
    plt.figure(figsize=(12, 6))
    sns.violinplot(data=combined_data, x='condition', y=loss_col, palette='Set3')
    plt.title('å¤šæ¡ä»¶ Loss åˆ†å¸ƒå¯¹æ¯” (å°æç´å›¾)')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.savefig(os.path.join(out_dir, "comparison_violin.png"), dpi=150)
    plt.close()
    
    # 3) é‡å çš„ç›´æ–¹å›¾+KDE
    plt.figure(figsize=(10, 6))
    colors = plt.cm.Set1(np.linspace(0, 1, len(conditions_list)))
    for i, (_, group) in enumerate(combined_data.groupby('condition')):
        vals = group[loss_col].dropna()
        plt.hist(vals, bins=30, alpha=0.6, label=group['condition'].iloc[0], 
                color=colors[i], density=True)
        try:
            sns.kdeplot(vals, color=colors[i], linewidth=2)
        except:
            pass
    plt.xlabel(loss_col)
    plt.ylabel('Density')
    plt.title('å¤šæ¡ä»¶ Loss åˆ†å¸ƒå¯¹æ¯” (é‡å ç›´æ–¹å›¾+KDE)')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.tight_layout()
    plt.savefig(os.path.join(out_dir, "comparison_hist_kde.png"), dpi=150, bbox_inches='tight')
    plt.close()
    
    # 4) ECDF å¯¹æ¯”
    plt.figure(figsize=(10, 6))
    for i, (_, group) in enumerate(combined_data.groupby('condition')):
        vals = group[loss_col].dropna()
        try:
            sns.ecdfplot(vals, label=group['condition'].iloc[0], color=colors[i], linewidth=2)
        except:
            pass
    plt.xlabel(loss_col)
    plt.ylabel('ç´¯ç§¯æ¦‚ç‡')
    plt.title('å¤šæ¡ä»¶ Loss åˆ†å¸ƒå¯¹æ¯” (ECDF)')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.tight_layout()
    plt.savefig(os.path.join(out_dir, "comparison_ecdf.png"), dpi=150, bbox_inches='tight')
    plt.close()
    
    # 5) ç»Ÿè®¡é‡å¯¹æ¯”æŸ±çŠ¶å›¾
    plt.figure(figsize=(15, 5))
    metrics = ['mean', 'std', 'median']
    for i, metric in enumerate(metrics, 1):
        plt.subplot(1, 3, i)
        plt.bar(range(len(all_stats)), [s[metric] for s in all_stats], color=colors[:len(all_stats)])
        plt.title(f'{metric.capitalize()} å¯¹æ¯”')
        plt.xticks(range(len(all_stats)), [s['condition'] for s in all_stats], rotation=45, ha='right')
        plt.ylabel(metric)
    plt.suptitle('å…³é”®ç»Ÿè®¡é‡å¯¹æ¯”')
    plt.tight_layout()
    plt.savefig(os.path.join(out_dir, "comparison_stats_bar.png"), dpi=150, bbox_inches='tight')
    plt.close()
    
    # ä¿å­˜åˆå¹¶æ•°æ®ä¸º CSV
    combined_data.to_csv(os.path.join(out_dir, "comparison_data.csv"), index=False)
    
    print(f"âœ… å·²å®Œæˆ {len(conditions_list)} ä¸ªæ¡ä»¶çš„å¯¹æ¯”åˆ†æï¼Œè¾“å‡ºä¿å­˜åœ¨ {out_dir}/")
    print("ğŸ“Š ç”Ÿæˆçš„å¯¹æ¯”å›¾è¡¨ï¼š")
    print("  - comparison_boxplot.png: ç®±çº¿å›¾å¯¹æ¯”")
    print("  - comparison_violin.png: å°æç´å›¾å¯¹æ¯”") 
    print("  - comparison_hist_kde.png: é‡å ç›´æ–¹å›¾+KDEå¯¹æ¯”")
    print("  - comparison_ecdf.png: ECDFå¯¹æ¯”")
    print("  - comparison_stats_bar.png: ç»Ÿè®¡é‡æŸ±çŠ¶å›¾å¯¹æ¯”")
    
    return combined_stats_df, combined_data


def auto_pairwise_analysis(df, switch_cols, base_out_dir="auto_pairwise_analysis", loss_col='eval/loss'):
    """
    è‡ªåŠ¨å¯¹æ‰€æœ‰å¼€å…³ä¸¤ä¸¤ç»„åˆè¿›è¡Œå››çŠ¶æ€å¯¹æ¯”åˆ†æï¼ˆ00, 01, 10, 11ï¼‰ã€‚
    
    å‚æ•°:
    - df: åŸå§‹ DataFrameï¼ˆåŒ…å«å¼€å…³åˆ—ä¸ `loss_col`ï¼‰
    - switch_cols: æ‰€æœ‰å¼€å…³åˆ—ååˆ—è¡¨
    - base_out_dir: åŸºç¡€è¾“å‡ºç›®å½•ï¼Œå…¶ä¸‹ä¼šåˆ›å»ºå„ä¸ªä¸¤ä¸¤ç»„åˆçš„å­æ–‡ä»¶å¤¹
    - loss_col: è¦åˆ†æçš„æŸå¤±åˆ—åï¼ˆé»˜è®¤ 'eval/loss'ï¼‰
    
    è¿”å›:
    - summary_results: åŒ…å«æ‰€æœ‰ç»„åˆåˆ†æç»“æœæ‘˜è¦çš„ DataFrame
    """
    import itertools
    import os
    
    os.makedirs(base_out_dir, exist_ok=True)
    
    all_summaries = []
    total_pairs = len(list(itertools.combinations(switch_cols, 2)))
    
    print(f"ğŸš€ å¼€å§‹è‡ªåŠ¨ä¸¤ä¸¤ç»„åˆåˆ†æï¼Œå…± {total_pairs} ä¸ªç»„åˆ...")
    
    for idx, (switch1, switch2) in enumerate(itertools.combinations(switch_cols, 2), 1):
        print(f"\nğŸ“Š å¤„ç†ç»„åˆ {idx}/{total_pairs}: {switch1} vs {switch2}")
        
        # åˆ›å»ºå­æ–‡ä»¶å¤¹
        pair_dir = os.path.join(base_out_dir, f"{switch1}_vs_{switch2}")
        os.makedirs(pair_dir, exist_ok=True)
        
        # å®šä¹‰å››ç§çŠ¶æ€æ¡ä»¶
        conditions = [
            {
                'switch_list': [switch1, switch2],
                'value_list': [0, 0],
                'label': f'{switch1}=0, {switch2}=0'
            },
            {
                'switch_list': [switch1, switch2],
                'value_list': [0, 1],
                'label': f'{switch1}=0, {switch2}=1'
            },
            {
                'switch_list': [switch1, switch2],
                'value_list': [1, 0],
                'label': f'{switch1}=1, {switch2}=0'
            },
            {
                'switch_list': [switch1, switch2],
                'value_list': [1, 1],
                'label': f'{switch1}=1, {switch2}=1'
            }
        ]
        
        try:
            # è°ƒç”¨å¯¹æ¯”åˆ†æ
            compare_stats_df, compare_data = compare_fixed_switches(
                df, conditions, out_dir=pair_dir, loss_col=loss_col
            )
            
            if not compare_stats_df.empty:
                # æå–å…³é”®ä¿¡æ¯ç”¨äºæ€»ç»“
                best_condition_idx = compare_stats_df['mean'].idxmin()
                best_condition = compare_stats_df.iloc[best_condition_idx]
                worst_condition_idx = compare_stats_df['mean'].idxmax()
                worst_condition = compare_stats_df.iloc[worst_condition_idx]
                
                summary_info = {
                    'switch1': switch1,
                    'switch2': switch2,
                    'pair_dir': pair_dir,
                    'total_conditions': len(compare_stats_df),
                    'best_condition': best_condition['condition'],
                    'best_mean_loss': best_condition['mean'],
                    'best_count': best_condition['count'],
                    'worst_condition': worst_condition['condition'],
                    'worst_mean_loss': worst_condition['mean'],
                    'worst_count': worst_condition['count'],
                    'loss_range': worst_condition['mean'] - best_condition['mean'],
                    'overall_mean': compare_stats_df['mean'].mean(),
                    'overall_std': compare_stats_df['mean'].std()
                }
                all_summaries.append(summary_info)
                
                # ä¿å­˜è¯¥ç»„åˆçš„è¯¦ç»†ç»Ÿè®¡åˆ°å­æ–‡ä»¶å¤¹
                compare_stats_df.to_excel(os.path.join(pair_dir, "detailed_stats.xlsx"), index=False)
                
                print(f"âœ… å®Œæˆ {switch1} vs {switch2}ï¼Œæœ€ä½³é…ç½®ï¼š{best_condition['condition']} (loss={best_condition['mean']:.4f})")
            else:
                print(f"âš ï¸ {switch1} vs {switch2} æ²¡æœ‰äº§ç”Ÿæœ‰æ•ˆç»“æœ")
                
        except Exception as e:
            print(f"âŒ å¤„ç† {switch1} vs {switch2} æ—¶å‡ºé”™: {str(e)}")
            continue
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    if all_summaries:
        summary_df = pd.DataFrame(all_summaries)
        
        # æŒ‰ loss_range é™åºæ’åˆ—ï¼Œæ‰¾å‡ºå½±å“æœ€å¤§çš„ç»„åˆ
        summary_df = summary_df.sort_values('loss_range', ascending=False)
        
        # ä¿å­˜æ€»ç»“æŠ¥å‘Š
        summary_df.to_excel(os.path.join(base_out_dir, "pairwise_analysis_summary.xlsx"), index=False)
        
        # ç”Ÿæˆ Top æ’è¡Œæ¦œ
        print(f"\nğŸ“ˆ è‡ªåŠ¨ä¸¤ä¸¤ç»„åˆåˆ†æå®Œæˆï¼æ€»å…±å¤„ç†äº† {len(all_summaries)} ä¸ªæœ‰æ•ˆç»„åˆ")
        print("\nğŸ† å½±å“æœ€å¤§çš„å‰5ä¸ªå¼€å…³ç»„åˆï¼ˆæŒ‰losså·®å¼‚æ’åºï¼‰ï¼š")
        top5 = summary_df.head(5)
        for _, row in top5.iterrows():
            print(f"  {row['switch1']} vs {row['switch2']}: lossèŒƒå›´ {row['loss_range']:.4f} "
                  f"(æœ€ä½³: {row['best_condition']}, loss={row['best_mean_loss']:.4f})")
        
        # ç”Ÿæˆå½±å“æ’è¡Œå›¾è¡¨
        plt.figure(figsize=(12, 8))
        top10 = summary_df.head(10)
        y_pos = np.arange(len(top10))
        plt.barh(y_pos, top10['loss_range'], color='skyblue')
        plt.yticks(y_pos, [f"{row['switch1']} vs {row['switch2']}" for _, row in top10.iterrows()])
        plt.xlabel('Loss Range (æœ€å¤§å·®å¼‚)')
        plt.title('å¼€å…³ç»„åˆå½±å“åŠ›æ’è¡Œæ¦œ (Top 10)')
        plt.gca().invert_yaxis()
        plt.tight_layout()
        plt.savefig(os.path.join(base_out_dir, "top_influential_pairs.png"), dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"\nğŸ’¾ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° {base_out_dir}/")
        print("ğŸ“ æ–‡ä»¶ç»“æ„ï¼š")
        print(f"  - pairwise_analysis_summary.xlsx: æ€»ç»“æŠ¥å‘Š")
        print(f"  - top_influential_pairs.png: å½±å“åŠ›æ’è¡Œå›¾")
        print(f"  - å„å­æ–‡ä»¶å¤¹: æ¯ä¸ªå¼€å…³ç»„åˆçš„è¯¦ç»†å¯¹æ¯”åˆ†æ")
        
        return summary_df
    else:
        print("âš ï¸ æ²¡æœ‰ç”Ÿæˆä»»ä½•æœ‰æ•ˆçš„åˆ†æç»“æœ")
        return pd.DataFrame()


def main():
    df, switch_cols, df_switch, y_loss, y_acc = load_data()

    X = df_switch.copy()
    y = y_loss
    model, explainer, shap_values = train_xgb_and_shap(X, y)

    #plot_shap_summary(shap_values, X)
    #top5 = top5_recommendation(df, switch_cols)
    #shap_interaction, interaction_matrix = compute_shap_interactions(explainer, X, switch_cols)
    #three_model_df = compute_three_way_model_interactions(model, X, switch_cols, sample_size=200, out_file="three_way_model_interactions.xlsx")
    #summary2_df = pairwise_scan(df, X, shap_values, shap_interaction, switch_cols)
    #summary3_df = three_way_scan(df, X, shap_interaction, switch_cols)
    
    # è”åˆå¯¹æ¯”åˆ†æç¤ºä¾‹
    '''
    conditions = [
        {
            'switch_list': ['untie_attn_weights', 'use_rms_norm'],
            'value_list': [1, 0],
            'label': 'untie_attn=1, rms_norm=0'
        },
        {
            'switch_list': ['untie_attn_weights', 'use_rms_norm'],
            'value_list': [1, 1],
            'label': 'untie_attn=1, rms_norm=1'
        }
    ]
    compare_stats_df, compare_data = compare_fixed_switches(df, conditions, out_dir="comparison_analysis_13")
    '''

    # è‡ªåŠ¨ä¸¤ä¸¤ç»„åˆåˆ†æç¤ºä¾‹
    auto_summary_df = auto_pairwise_analysis(df, switch_cols, base_out_dir="auto_pairwise_analysis")

if __name__ == "__main__":
    main()


